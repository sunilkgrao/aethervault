//! Benchmark demonstrating the performance benefit of embedding caching.
//!
//! This example compares performance with and without caching for repeated texts.
//!
//! ## Prerequisites
//!
//! Download the BGE-small model:
//!
//! ```bash
//! mkdir -p ~/.cache/vault/text-models
//! curl -L 'https://huggingface.co/BAAI/bge-small-en-v1.5/resolve/main/onnx/model.onnx' \
//!   -o ~/.cache/vault/text-models/bge-small-en-v1.5.onnx
//! curl -L 'https://huggingface.co/BAAI/bge-small-en-v1.5/resolve/main/tokenizer.json' \
//!   -o ~/.cache/vault/text-models/bge-small-en-v1.5_tokenizer.json
//! ```
//!
//! ## Run
//!
//! ```bash
//! cargo run --example text_embed_cache_bench --features vec --release
//! ```

use aether_core::Result;
#[cfg(feature = "vec")]
use aether_core::text_embed::{LocalTextEmbedder, TextEmbedConfig};
use std::time::Instant;

fn main() -> Result<()> {
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘  Embedding Cache Benchmark                                â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    // Test texts with intentional repeats
    let test_texts = vec![
        "machine learning",
        "artificial intelligence",
        "deep learning",
        "neural networks",
        "natural language processing",
        "machine learning",        // Repeat 1
        "artificial intelligence", // Repeat 2
        "computer vision",
        "deep learning",    // Repeat 3
        "machine learning", // Repeat 4
    ];

    println!(
        "Test data: {} texts ({} unique, {} repeats)\n",
        test_texts.len(),
        7, // unique
        3
    ); // repeats

    // ---------- Test with Cache Enabled ----------
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("Test 1: WITH Cache (enabled by default)");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");

    let config_cached = TextEmbedConfig::default();
    let embedder_cached = LocalTextEmbedder::new(config_cached)?;

    println!("Processing texts...");
    let start = Instant::now();
    for (i, text) in test_texts.iter().enumerate() {
        let _ = embedder_cached.encode_text(text)?;
        if i < test_texts.len() - 1 {
            print!(".");
        }
    }
    println!("!");
    let cached_time = start.elapsed();

    if let Some(stats) = embedder_cached.cache_stats() {
        println!("\nğŸ“Š Cache Statistics:");
        println!("   Hits:      {}", stats.hits);
        println!("   Misses:    {}", stats.misses);
        println!("   Size:      {}/{}", stats.size, stats.capacity);
        println!("   Hit Rate:  {:.1}%", stats.hit_rate() * 100.0);
    }

    println!("\nâ±ï¸  Total Time: {:?}", cached_time);

    // ---------- Test with Cache Disabled ----------
    println!("\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("Test 2: WITHOUT Cache (force disabled)");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");

    let config_uncached = TextEmbedConfig {
        enable_cache: false,
        ..Default::default()
    };
    let embedder_uncached = LocalTextEmbedder::new(config_uncached)?;

    println!("Processing texts...");
    let start = Instant::now();
    for (i, text) in test_texts.iter().enumerate() {
        let _ = embedder_uncached.encode_text(text)?;
        if i < test_texts.len() - 1 {
            print!(".");
        }
    }
    println!("!");
    let uncached_time = start.elapsed();

    println!("\nâ±ï¸  Total Time: {:?}", uncached_time);

    // ---------- Results ----------
    println!("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘  Results                                                   â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    let speedup = uncached_time.as_secs_f64() / cached_time.as_secs_f64();

    println!("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    println!("â”‚ Configuration  â”‚ Time         â”‚ Speedup      â”‚");
    println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
    println!(
        "â”‚ With Cache     â”‚ {:>10.3}s â”‚ {:>9.2}x â”‚",
        cached_time.as_secs_f64(),
        speedup
    );
    println!(
        "â”‚ Without Cache  â”‚ {:>10.3}s â”‚     baseline â”‚",
        uncached_time.as_secs_f64()
    );
    println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");

    if speedup > 1.0 {
        println!("âœ… Cache provides {:.1}% speedup!", (speedup - 1.0) * 100.0);
    } else {
        println!("âš ï¸  No speedup observed (may indicate all cache misses)");
    }

    println!("\nğŸ’¡ Note: Speedup increases with more repeated texts.");
    println!("   Real-world applications with 50-90% repeated queries");
    println!("   can see 2-10x improvements!\n");

    Ok(())
}
